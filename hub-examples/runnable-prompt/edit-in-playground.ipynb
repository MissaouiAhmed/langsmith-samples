{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "0tq8MDVIeABr"
      },
      "source": [
        "# Runnable PromptTemplates\n",
        "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langsmith-cookbook/blob/main/hub-examples/runnable-prompt/edit-in-playground.ipynb)\n",
        "\n",
        "When you build a chain using LangChain [runnables](https://python.langchain.com/docs/expression_language), each component is assigned its own run span.\n",
        "\n",
        "This means you can modify and run prompts directly in the playground. You can also save and version them in the hub for later use.\n",
        "\n",
        "In this example, you will build a simple chain using runnables, save the prompt trace to the hub, and then use the versioned prompt within your chain. The prompt will look something like the following:\n",
        "\n",
        "[![Chat Prompt Repo](https://github.com/langchain-ai/langsmith-cookbook/blob/main/hub-examples/runnable-prompt/img/prompt_repo.png?raw=1)](https://smith.langchain.com/hub/wfh/enigma-prompt)\n",
        "\n",
        "Using runnables in the playground make it easy to experiment quickly with different prompts and to share them with your team, especially for those who prefer to not dive deep into the code.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before you start, make sure you have a LangSmith account and an API key (for your personal \"organization\"). For more information on getting started, check out the [docs](https://docs.smith.langchain.com/hub/quickstart)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ilrxjYnxeABv"
      },
      "outputs": [],
      "source": [
        "%pip install -U langchain langchainhub  --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade anthropic"
      ],
      "metadata": {
        "id": "lXCNdAkIi7P2",
        "outputId": "eafe4455-2fab-48f1-b0b6-8dd58227e34a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.11/dist-packages (0.49.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from anthropic) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.27.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": [],
        "id": "S-1UD2Z8eABy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "# Update with your API URL if using a hosted instance of Langsmith.\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')s\n",
        "# Update with your API URL if using a hosted instance of Langsmith.\n",
        "os.environ[\"LANGCHAIN_HUB_API_URL\"] = \"https://api.hub.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_HUB_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = userdata.get('ANTHROPIC_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ymlNOjZeAB0"
      },
      "source": [
        "## 1. Define your chain\n",
        "\n",
        "First, define the chain you want to trace. We will start with a simple prompt and chat-model combination.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [],
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "MJ_fyhnAeAB1",
        "outputId": "ce1b986e-b4cc-4499-b661-1d879d018b25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-b6c3953cc8c5>:15: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  chain = prompt | ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=1)\n"
          ]
        }
      ],
      "source": [
        "from langchain import prompts, hub\n",
        "import anthropic\n",
        "from langchain_community.chat_models import ChatAnthropic\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "\n",
        "\n",
        "prompt = prompts.ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a mysteriously vague oracle who only speaks in riddles.\"),\n",
        "        (\"human\", \"{input}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "chain = prompt | ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "xvZkaJpQeAB2"
      },
      "source": [
        "The pipe \"|\" syntax above converts the prompt and chat model into a [RunnableSequence](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.RunnableSequence.html) for easy composition.\n",
        "\n",
        "Run the chain below. We will use the [collect_runs](https://api.python.langchain.com/en/latest/tracers/langchain_core.tracers.context.collect_runs.html) callback to retrieve the run ID of the traced run and share it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZcWAIbr4eAB4",
        "outputId": "7f222c65-61e8-46b1-dae5-5179f07ccd47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The serpent coils tightly around the heart of the machine, binding its power in a dance of limitation and concurrency."
          ]
        }
      ],
      "source": [
        "from langchain import callbacks\n",
        "\n",
        "with callbacks.collect_runs() as cb:\n",
        "    for chunk in chain.stream({\"input\": \"What is the GIL?\"}):\n",
        "        print(chunk.content, end=\"\", flush=True)\n",
        "    run_id = cb.traced_runs[0].id"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}